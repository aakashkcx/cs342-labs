{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS342 Machine Learning\n",
    "# Lab 3: _K_-NN classification\n",
    "\n",
    "## Department of Computer Science, University of Warwick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the this lab, we will explore the use and implementation of a _K_-NN classifier and _k_-fold validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data files for the lab\n",
    "\n",
    "If working on one of the DCS machines, the data may be found here:\n",
    "\n",
    "```/modules/cs342/2020/lab3/data/diabetes.data ```\n",
    "\n",
    "You may load the data directly from that directory.\n",
    "\n",
    "If you are using your own machine, copy the data across by running the following command in a terminal window using the remote node corresponding to your username. The name of this remote node uses the last two digits of your username in the form remote-nn, for example, if your username is u1234567 you would connect to remote-67.dcs.warwick.ac.uk (recall to use your USERNAME and correpsonding REMOTE_NN):\n",
    "\n",
    "```scp USERNAME@REMOTE_NN.dcs.warwick.ac.uk:/modules/cs342/2020/lab3/data/* .```\n",
    "\n",
    "After entering your DCS password, this will copy the data to your current working directory. You should now have the following files:\n",
    "```\n",
    "├──[your working directory]\n",
    "   └── diabetes.data\n",
    "```\n",
    "**Please make sure to use the correct path to these files when working on your own machine. The scripts below assume you are working on the DCS machines. Recall that the *.ipynb file (this file) should be in your working directory.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _K_-NN classification\n",
    "\n",
    " \n",
    "We will use the Diabetes dataset from the UCI Machine Learning Repository (file *diabetes.data*). Our goal is to predict if female patients will test positive for diabetes given 8 attributes, including age and blood pressure. For more details on the dataset see: https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset ( _diabetes.data_ ) into a Pandas data frame and standardise the attributes: for each attribute, or feature, compute its mean and standard deviation (see Lab 1) and replace each feature value by:\n",
    "\n",
    "(value - mean)/standard_deviation. \n",
    "\n",
    "Note that the last column corresponds to the class label: 1 for the positive class and 0 for the negative class. Also note that the _*.data_ file has no header. By default, Pandas will read the first row of a _.data_ file as the column name. This behaviour can be disabled by modifying the header argument. See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6  \\\n",
      "0    0.639530  0.847771  0.149543  0.906679 -0.692439  0.203880  0.468187   \n",
      "1   -0.844335 -1.122665 -0.160441  0.530556 -0.692439 -0.683976 -0.364823   \n",
      "2    1.233077  1.942458 -0.263769 -1.287373 -0.692439 -1.102537  0.604004   \n",
      "3   -0.844335 -0.997558 -0.160441  0.154433  0.123221 -0.493721 -0.920163   \n",
      "4   -1.141108  0.503727 -1.503707  0.906679  0.765337  1.408828  5.481337   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "763  1.826623 -0.622237  0.356200  1.721613  0.869464  0.115094 -0.908090   \n",
      "764 -0.547562  0.034575  0.046215  0.405181 -0.692439  0.609757 -0.398023   \n",
      "765  0.342757  0.003299  0.149543  0.154433  0.279412 -0.734711 -0.684747   \n",
      "766 -0.844335  0.159683 -0.470426 -1.287373 -0.692439 -0.240048 -0.370859   \n",
      "767 -0.844335 -0.872451  0.046215  0.655930 -0.692439 -0.201997 -0.473476   \n",
      "\n",
      "            7  \n",
      "0    1.425067  \n",
      "1   -0.190548  \n",
      "2   -0.105515  \n",
      "3   -1.040871  \n",
      "4   -0.020483  \n",
      "..        ...  \n",
      "763  2.530487  \n",
      "764 -0.530677  \n",
      "765 -0.275580  \n",
      "766  1.169970  \n",
      "767 -0.870806  \n",
      "\n",
      "[768 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import diabetes dataset\n",
    "diabetes = pd.read_csv(\"./diabetes.data\", header=None)\n",
    "\n",
    "# standardise attributes (subtract the mean and divide by the standard deviation)\n",
    "standardised = (diabetes - diabetes.mean()) / diabetes.std()\n",
    "\n",
    "# DO NOT INCLUDE THE CLASS LABEL\n",
    "X = standardised.drop(8, axis=1)\n",
    "y = diabetes[8]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our two classes, i.e.,  the negative class and the positive class, write a function that takes as input your predicted targets and the true targets (i.e., the ground truth), and estimates the *Accuracy* of the classifier,\n",
    "defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    " Accuracy = \\frac{TP + TN}{TP + FN + FP + TN},\n",
    "\\end{equation*}\n",
    "\n",
    "where $TP$ = No. of True Positives (model predicts positive and true value is positive), $FP$ = No. of False Positives (model predicts positive and true value is negative), $TN$ = No. of True Negatives (model predicts negative and true value is negative), and $FN$ = No. of False Negatives (model predicts negative and true value is positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform _K_-NN classification using the scikit implementation (*sklearn.neighbors.KNeighborsClassifier* ) for\n",
    "_K_ = {1, 2, 3, 4, 5}. Use 10-fold cross-validation ( _sklearn.model_selection_ ) to choose the best value of _K_. Make sure to display the accuracy value of each classifier. Which is the most accurate classifier based on 10-fold cross-validation?\n",
    "\n",
    "**Hint:** You may find that the *KFold* function within *sklearn.model_selection* is useful to keep track of\n",
    "the samples assigned to each fold when performing 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1: 0.708321941216678\n",
      "k = 2: 0.7173786739576214\n",
      "k = 3: 0.7460526315789473\n",
      "k = 4: 0.73298017771702\n",
      "k = 5: 0.7421394395078605\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define function to  calculate accuracy\n",
    "\n",
    "def accuracy(predicted: numpy.ndarray, true: numpy.ndarray) -> float:\n",
    "    test = predicted == true\n",
    "    return sum(test) / len(test)\n",
    "\n",
    "\n",
    "# define function to perform K-NN classification using k-fold validation\n",
    "\n",
    "def knn(k: int, X: pd.DataFrame, y: pd.Series, test: pd.DataFrame):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X, y)\n",
    "    return neigh.predict(test)\n",
    "\n",
    "def tenfold(k: int, X: pd.DataFrame, y: pd.DataFrame):\n",
    "    kf = KFold(n_splits=10, random_state=None)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        prediction = knn(k, X_train, y_train, X_test)\n",
    "        accuracies.append(accuracy(prediction, y_test))\n",
    "    return sum(accuracies) / len(accuracies)\n",
    "\n",
    "\n",
    "# cross-validate with K = 1, 2, 3, 4, and 5\n",
    "\n",
    "for k in range(1, 6):\n",
    "    print(f\"k = {k}:\", tenfold(k, X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
